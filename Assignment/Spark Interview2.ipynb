{"cells":[{"cell_type":"code","source":["sc"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c24e863c-ddda-41bd-b049-c54edd4852df"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=1460199518901902#setting/sparkui/0912-123157-mt7gxxnf/driver-1629945251902109700\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.2.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        ","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=1460199518901902#setting/sparkui/0912-123157-mt7gxxnf/driver-1629945251902109700\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.2.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        "]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nfrom pyspark.sql import SparkSession\n\n\npivotDF = spark.read.format(\"com.crealytics.spark.excel\").option(\"header\",\"true\").option(\"inferSchema\",\"true\")\\\n    .load(\"dbfs:/FileStore/tables/Pyspark_Task.xlsx\")\n\npivotDF.show(truncate=False)\n\n\"\"\"data2 = [(\"P1\",\"PL1\",20000,25000,19000,22000,23000,13000,12000,13000,13500,14000),\n    (\"P2\",\"PL1\",80000,90000,75000,78000,100000,18000,18000,18000,18000,18000),\n    (\"P3\",\"PL3\",35000,32000,56000,40000,42000,17000,20000,16000,15000,15000),\n    (\"P4\",\"PL2\",15000,23000,42000,12000,13000,13000,13000,13000,13000,13000),\n    (\"P5\",\"PL1\",85000,19000,24000,15000,13000,20000,22000,23000,23000,21000)]\n\nschema = StructType([StructField(\"Product\",StringType(),True),\n                    StructField(\"Plant Name\",StringType(),True),\n                    StructField(\"Sales_18\",IntegerType(),True),\n                    StructField(\"Sales_19\",IntegerType(),True),\n                    StructField(\"Sales_20\",IntegerType(),True),\n                    StructField(\"Sales_21\",IntegerType(),True),\n                    StructField(\"Sales_22\",IntegerType(),True),\n                    StructField(\"Inv_18\",IntegerType(),True),\n                    StructField(\"Inv_19\",IntegerType(),True),\n                    StructField(\"Inv_20\",IntegerType(),True),\n                    StructField(\"Inv_21\",IntegerType(),True),\n                    StructField(\"Inv_22\",IntegerType(),True)])\n \npivotDF = spark.createDataFrame(data=data2,schema=schema)\"\"\"\n#pivotDF.printSchema()\n\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"55ba9ea2-6a32-4f47-9e4b-46386be9e701"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------+----------+--------+--------+--------+--------+--------+-------+-------+-------+-------+-------+\n|Product|Plant Name|Sales_18|Sales_19|Sales_20|Sales_21|Sales_22|Inv_18 |Inv_19 |Inv_20 |Inv_21 |Inv_22 |\n+-------+----------+--------+--------+--------+--------+--------+-------+-------+-------+-------+-------+\n|P1     |PL1       |20000.0 |25000.0 |19000.0 |22000.0 |23000.0 |13000.0|12000.0|13000.0|13500.0|14000.0|\n|P2     |PL1       |80000.0 |90000.0 |75000.0 |78000.0 |100000.0|18000.0|18000.0|18000.0|18000.0|18000.0|\n|P3     |PL3       |35000.0 |32000.0 |56000.0 |40000.0 |42000.0 |17000.0|20000.0|16000.0|15000.0|15000.0|\n|P4     |PL2       |15000.0 |23000.0 |42000.0 |12000.0 |13000.0 |13000.0|13000.0|13000.0|13000.0|13000.0|\n|P5     |PL1       |85000.0 |19000.0 |24000.0 |15000.0 |13000.0 |20000.0|22000.0|23000.0|23000.0|21000.0|\n+-------+----------+--------+--------+--------+--------+--------+-------+-------+-------+-------+-------+\n\nOut[1]: 'data2 = [(\"P1\",\"PL1\",20000,25000,19000,22000,23000,13000,12000,13000,13500,14000),\\n    (\"P2\",\"PL1\",80000,90000,75000,78000,100000,18000,18000,18000,18000,18000),\\n    (\"P3\",\"PL3\",35000,32000,56000,40000,42000,17000,20000,16000,15000,15000),\\n    (\"P4\",\"PL2\",15000,23000,42000,12000,13000,13000,13000,13000,13000,13000),\\n    (\"P5\",\"PL1\",85000,19000,24000,15000,13000,20000,22000,23000,23000,21000)]\\n\\nschema = StructType([StructField(\"Product\",StringType(),True),\\n                    StructField(\"Plant Name\",StringType(),True),\\n                    StructField(\"Sales_18\",IntegerType(),True),\\n                    StructField(\"Sales_19\",IntegerType(),True),\\n                    StructField(\"Sales_20\",IntegerType(),True),\\n                    StructField(\"Sales_21\",IntegerType(),True),\\n                    StructField(\"Sales_22\",IntegerType(),True),\\n                    StructField(\"Inv_18\",IntegerType(),True),\\n                    StructField(\"Inv_19\",IntegerType(),True),\\n                    StructField(\"Inv_20\",IntegerType(),True),\\n                    StructField(\"Inv_21\",IntegerType(),True),\\n                    StructField(\"Inv_22\",IntegerType(),True)])\\n \\npivotDF = spark.createDataFrame(data=data2,schema=schema)'","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------+----------+--------+--------+--------+--------+--------+-------+-------+-------+-------+-------+\n|Product|Plant Name|Sales_18|Sales_19|Sales_20|Sales_21|Sales_22|Inv_18 |Inv_19 |Inv_20 |Inv_21 |Inv_22 |\n+-------+----------+--------+--------+--------+--------+--------+-------+-------+-------+-------+-------+\n|P1     |PL1       |20000.0 |25000.0 |19000.0 |22000.0 |23000.0 |13000.0|12000.0|13000.0|13500.0|14000.0|\n|P2     |PL1       |80000.0 |90000.0 |75000.0 |78000.0 |100000.0|18000.0|18000.0|18000.0|18000.0|18000.0|\n|P3     |PL3       |35000.0 |32000.0 |56000.0 |40000.0 |42000.0 |17000.0|20000.0|16000.0|15000.0|15000.0|\n|P4     |PL2       |15000.0 |23000.0 |42000.0 |12000.0 |13000.0 |13000.0|13000.0|13000.0|13000.0|13000.0|\n|P5     |PL1       |85000.0 |19000.0 |24000.0 |15000.0 |13000.0 |20000.0|22000.0|23000.0|23000.0|21000.0|\n+-------+----------+--------+--------+--------+--------+--------+-------+-------+-------+-------+-------+\n\nOut[1]: 'data2 = [(\"P1\",\"PL1\",20000,25000,19000,22000,23000,13000,12000,13000,13500,14000),\\n    (\"P2\",\"PL1\",80000,90000,75000,78000,100000,18000,18000,18000,18000,18000),\\n    (\"P3\",\"PL3\",35000,32000,56000,40000,42000,17000,20000,16000,15000,15000),\\n    (\"P4\",\"PL2\",15000,23000,42000,12000,13000,13000,13000,13000,13000,13000),\\n    (\"P5\",\"PL1\",85000,19000,24000,15000,13000,20000,22000,23000,23000,21000)]\\n\\nschema = StructType([StructField(\"Product\",StringType(),True),\\n                    StructField(\"Plant Name\",StringType(),True),\\n                    StructField(\"Sales_18\",IntegerType(),True),\\n                    StructField(\"Sales_19\",IntegerType(),True),\\n                    StructField(\"Sales_20\",IntegerType(),True),\\n                    StructField(\"Sales_21\",IntegerType(),True),\\n                    StructField(\"Sales_22\",IntegerType(),True),\\n                    StructField(\"Inv_18\",IntegerType(),True),\\n                    StructField(\"Inv_19\",IntegerType(),True),\\n                    StructField(\"Inv_20\",IntegerType(),True),\\n                    StructField(\"Inv_21\",IntegerType(),True),\\n                    StructField(\"Inv_22\",IntegerType(),True)])\\n \\npivotDF = spark.createDataFrame(data=data2,schema=schema)'"]}}],"execution_count":0},{"cell_type":"code","source":["unpivotExpr = \"stack(10,'Sales_18',Sales_18, 'Sales_19',Sales_19, 'Sales_20',Sales_20, 'Sales_21',Sales_21, 'Sales_22',Sales_22,'Inv_18',Inv_18, 'Inv_19',Inv_19, 'Inv_20',Inv_20,'Inv_21',Inv_21, 'Inv_22',Inv_22) as (Metric,Value)\"\n\n\nunPivotDF = pivotDF.select('Product','Plant Name',expr(unpivotExpr)).where(\"Value is not null\")\nunPivotDF.show(100,truncate=False)\n#unPivotDF.show(100)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"df13acba-27db-4125-99ea-ef3476bd2aee"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------+----------+--------+--------+\n|Product|Plant Name|Metric  |Value   |\n+-------+----------+--------+--------+\n|P1     |PL1       |Sales_18|20000.0 |\n|P1     |PL1       |Sales_19|25000.0 |\n|P1     |PL1       |Sales_20|19000.0 |\n|P1     |PL1       |Sales_21|22000.0 |\n|P1     |PL1       |Sales_22|23000.0 |\n|P1     |PL1       |Inv_18  |13000.0 |\n|P1     |PL1       |Inv_19  |12000.0 |\n|P1     |PL1       |Inv_20  |13000.0 |\n|P1     |PL1       |Inv_21  |13500.0 |\n|P1     |PL1       |Inv_22  |14000.0 |\n|P2     |PL1       |Sales_18|80000.0 |\n|P2     |PL1       |Sales_19|90000.0 |\n|P2     |PL1       |Sales_20|75000.0 |\n|P2     |PL1       |Sales_21|78000.0 |\n|P2     |PL1       |Sales_22|100000.0|\n|P2     |PL1       |Inv_18  |18000.0 |\n|P2     |PL1       |Inv_19  |18000.0 |\n|P2     |PL1       |Inv_20  |18000.0 |\n|P2     |PL1       |Inv_21  |18000.0 |\n|P2     |PL1       |Inv_22  |18000.0 |\n|P3     |PL3       |Sales_18|35000.0 |\n|P3     |PL3       |Sales_19|32000.0 |\n|P3     |PL3       |Sales_20|56000.0 |\n|P3     |PL3       |Sales_21|40000.0 |\n|P3     |PL3       |Sales_22|42000.0 |\n|P3     |PL3       |Inv_18  |17000.0 |\n|P3     |PL3       |Inv_19  |20000.0 |\n|P3     |PL3       |Inv_20  |16000.0 |\n|P3     |PL3       |Inv_21  |15000.0 |\n|P3     |PL3       |Inv_22  |15000.0 |\n|P4     |PL2       |Sales_18|15000.0 |\n|P4     |PL2       |Sales_19|23000.0 |\n|P4     |PL2       |Sales_20|42000.0 |\n|P4     |PL2       |Sales_21|12000.0 |\n|P4     |PL2       |Sales_22|13000.0 |\n|P4     |PL2       |Inv_18  |13000.0 |\n|P4     |PL2       |Inv_19  |13000.0 |\n|P4     |PL2       |Inv_20  |13000.0 |\n|P4     |PL2       |Inv_21  |13000.0 |\n|P4     |PL2       |Inv_22  |13000.0 |\n|P5     |PL1       |Sales_18|85000.0 |\n|P5     |PL1       |Sales_19|19000.0 |\n|P5     |PL1       |Sales_20|24000.0 |\n|P5     |PL1       |Sales_21|15000.0 |\n|P5     |PL1       |Sales_22|13000.0 |\n|P5     |PL1       |Inv_18  |20000.0 |\n|P5     |PL1       |Inv_19  |22000.0 |\n|P5     |PL1       |Inv_20  |23000.0 |\n|P5     |PL1       |Inv_21  |23000.0 |\n|P5     |PL1       |Inv_22  |21000.0 |\n+-------+----------+--------+--------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------+----------+--------+--------+\n|Product|Plant Name|Metric  |Value   |\n+-------+----------+--------+--------+\n|P1     |PL1       |Sales_18|20000.0 |\n|P1     |PL1       |Sales_19|25000.0 |\n|P1     |PL1       |Sales_20|19000.0 |\n|P1     |PL1       |Sales_21|22000.0 |\n|P1     |PL1       |Sales_22|23000.0 |\n|P1     |PL1       |Inv_18  |13000.0 |\n|P1     |PL1       |Inv_19  |12000.0 |\n|P1     |PL1       |Inv_20  |13000.0 |\n|P1     |PL1       |Inv_21  |13500.0 |\n|P1     |PL1       |Inv_22  |14000.0 |\n|P2     |PL1       |Sales_18|80000.0 |\n|P2     |PL1       |Sales_19|90000.0 |\n|P2     |PL1       |Sales_20|75000.0 |\n|P2     |PL1       |Sales_21|78000.0 |\n|P2     |PL1       |Sales_22|100000.0|\n|P2     |PL1       |Inv_18  |18000.0 |\n|P2     |PL1       |Inv_19  |18000.0 |\n|P2     |PL1       |Inv_20  |18000.0 |\n|P2     |PL1       |Inv_21  |18000.0 |\n|P2     |PL1       |Inv_22  |18000.0 |\n|P3     |PL3       |Sales_18|35000.0 |\n|P3     |PL3       |Sales_19|32000.0 |\n|P3     |PL3       |Sales_20|56000.0 |\n|P3     |PL3       |Sales_21|40000.0 |\n|P3     |PL3       |Sales_22|42000.0 |\n|P3     |PL3       |Inv_18  |17000.0 |\n|P3     |PL3       |Inv_19  |20000.0 |\n|P3     |PL3       |Inv_20  |16000.0 |\n|P3     |PL3       |Inv_21  |15000.0 |\n|P3     |PL3       |Inv_22  |15000.0 |\n|P4     |PL2       |Sales_18|15000.0 |\n|P4     |PL2       |Sales_19|23000.0 |\n|P4     |PL2       |Sales_20|42000.0 |\n|P4     |PL2       |Sales_21|12000.0 |\n|P4     |PL2       |Sales_22|13000.0 |\n|P4     |PL2       |Inv_18  |13000.0 |\n|P4     |PL2       |Inv_19  |13000.0 |\n|P4     |PL2       |Inv_20  |13000.0 |\n|P4     |PL2       |Inv_21  |13000.0 |\n|P4     |PL2       |Inv_22  |13000.0 |\n|P5     |PL1       |Sales_18|85000.0 |\n|P5     |PL1       |Sales_19|19000.0 |\n|P5     |PL1       |Sales_20|24000.0 |\n|P5     |PL1       |Sales_21|15000.0 |\n|P5     |PL1       |Sales_22|13000.0 |\n|P5     |PL1       |Inv_18  |20000.0 |\n|P5     |PL1       |Inv_19  |22000.0 |\n|P5     |PL1       |Inv_20  |23000.0 |\n|P5     |PL1       |Inv_21  |23000.0 |\n|P5     |PL1       |Inv_22  |21000.0 |\n+-------+----------+--------+--------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ff640d2c-2512-4b62-a779-fe0e15714a88"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Spark Interview2","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2815450109749642}},"nbformat":4,"nbformat_minor":0}
